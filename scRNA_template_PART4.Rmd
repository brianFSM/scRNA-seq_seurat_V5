---
output:
  html_document:
    pandoc_args: './common.yaml'
params:
  config.args: "./config.yaml"
---

# Part 4: clustering

## Load libraries
```{r load_libraries, warning=FALSE,error=FALSE,message=FALSE}
library(Seurat)
library(ggplot2)
library(kableExtra)
library(dplyr)
library(future)
library(yaml)

if (!require(DoubletFinder)) {
  install.packages("fields") 
  remotes::install_github("chris-mcginnis-ucsf/DoubletFinder", 
                          upgrade = FALSE, 
                          dependencies = FALSE)
}


```


```{r prepare_inline_variables, echo = FALSE}
# get the datetime and set it to variable
todays.date <- Sys.Date()
formatted.date <- format(todays.date, format="%B %d %Y")

config.args <- read_yaml(params$config.args)
```

```{r set_fig_dims, eval = FALSE, echo = FALSE}
knitr::opts_chunk$set(fig.width=14, fig.height=12, fig.align = "center") 
```


```{r user_vals, warning=FALSE,error=FALSE,message=FALSE, echo = FALSE}
r.obj.loc <- config.args$data$`rds-file-path`

num.pcs <- config.args$analysis$part4$num_pcs

run_tests <- config.args$analysis$run_tests
node.type <- config.args$analysis$node_type

batch.correction.method <- config.args$analysis$part3$batch_correction
run.sctransform = FALSE

if (batch.correction.method == "sctransform"){
  run.sctransform = TRUE
}

part3.suffix <- config.args$analysis$part3$part3_suffix
part4.suffix <- config.args$analysis$part4$part4_suffix

part4.rds.open.file <- config.args$analysis$part4$part4_rds_open_filename
part4.rds.open.file <- sub(".RDS", paste0(part3.suffix, ".RDS"), part4.rds.open.file )
part4.rds.open.path <- file.path(r.obj.loc, part4.rds.open.file)

part4.rds.save.file <- config.args$analysis$part4$part4_rds_save_filename
part4.rds.save.file <- sub(".RDS", paste0(part4.suffix, ".RDS"), part4.rds.save.file )
part4.rds.save.path <- file.path(r.obj.loc, part4.rds.save.file)

part4.file.for.report <- config.args$analysis$part4$part4_report_tables_filename
part4.file.for.report <- sub(".RData", paste0(part4.suffix, ".RData"), part4.file.for.report )
part4.file.report.path <- file.path(r.obj.loc, part4.file.for.report)

ggplot.directory.name <- config.args$analysis$part1$ggplot_dir
ggplot.directory <- file.path(r.obj.loc, ggplot.directory.name)
```

```{r define_save_plots, echo = FALSE}

save_png_plot <- function(plot, filename){
  save.path <- file.path(ggplot.directory, paste0("part4", part4.suffix, "_", filename))
  ggsave(save.path, plot)
}

```

### This report was generated on `r formatted.date`

* num.pcs: `r num.pcs`
* node.type: `r node.type`

* starting with rds object at `r part4.rds.open.path`
* saving rds object to `r part4.rds.save.path`
* saving file for report at `r part4.file.report.path`

```{r get_num_cores_available, echo = FALSE}
if (node.type == "compute"){
  # If using a compute node, then put this in the submission script:
  # export MC_CORES=${SLURM_NTASKS}
  num.cores.available <- as.numeric(Sys.getenv("SLURM_NTASKS"))
} else {
  library(parallel) 
  num.cores.available <- detectCores() 
}
```

## Load the Seurat object from part 3

```{r load_data, warning=FALSE,error=FALSE,message=FALSE}
experiment.aggregate <- readRDS(file=part4.rds.open.path)
```


## So how many features should we use? Use too few and your leaving out interesting variation that may define cell types, use too many and you add in noise? maybe?

Lets choose the first `r num.pcs`, based on our prior part.

```{r use_pcs, warning=FALSE,error=FALSE,message=FALSE}
use.pcs = 1:num.pcs
```

## Identifying clusters

Seurat implements an graph-based clustering approach. Distances between the cells are calculated based on previously identified PCs. 

The default method for identifying k-nearest neighbors has been changed in V4 to [annoy](https://github.com/spotify/annoy) ("Approximate Nearest Neighbors Oh Yeah!). This is an approximate nearest-neighbor approach that is widely used for high-dimensional analysis in many fields, including single-cell analysis. Extensive community benchmarking has shown that annoy substantially improves the speed and memory requirements of neighbor discovery, with negligible impact to downstream results. 



Seurat prior approach was heavily inspired by recent manuscripts which applied graph-based clustering approaches to scRNAseq data. Briefly, Seurat identified clusters of cells by a shared nearest neighbor (SNN) modularity optimization based clustering algorithm. First calculate k-nearest neighbors (KNN) and construct the SNN graph. Then optimize the modularity function to determine clusters. For a full description of the algorithms, see Waltman and van Eck (2013) The European Physical Journal B. You can switch back to using the previous default setting using nn.method="rann".


The FindClusters function implements the neighbor based clustering procedure, and contains a resolution parameter that sets the granularity of the downstream clustering, with increased values leading to a greater number of clusters. 

This implementation generates clusters at a range of different resolutions. You should pick one to do the rest of this rmd sheet, but the investigators can pick a different resolution and you can switch it up easily.

```{r find_neighbors_help, warning=FALSE,error=FALSE,message=FALSE, eval = FALSE}
?FindNeighbors
```

```{r find_neighbors, warning=FALSE,error=FALSE,message=FALSE}
DefaultAssay(experiment.aggregate) <- "integrated"
experiment.aggregate <- FindNeighbors(experiment.aggregate, reduction="pca", dims = use.pcs)

experiment.aggregate <- FindClusters(
    object = experiment.aggregate,
    resolution = seq(0.10,0.8,0.1),
    # resolution = 0.25,
    verbose = FALSE
)
```


Seurat add the clustering information to the metadata beginning with RNA_snn_res. followed by the resolution

```{r cluster_metadata, warning=FALSE,error=FALSE,message=FALSE}
head(experiment.aggregate[[]])
```


Lets first investigate how many clusters each resolution produces and set it to the smallest resolutions of 0.5 (fewest clusters).

```{r resolution_clust_num_table, warning=FALSE,error=FALSE,message=FALSE}
clusters.by.resolution.table <- sapply(grep("res",colnames(experiment.aggregate@meta.data),value = TRUE),
       function(x) length(unique(experiment.aggregate@meta.data[,x]))) %>% kable(caption = "Number of clusters by resolution", col.names = "Number of clusters", jalign = "c") %>% kable_styling()

clusters.by.resolution.table
```


## tSNE and uMAP
The 2 most popular options for dimensionality reduction graphs with single cell data are uMAP and tSNE. Brian tends to prefer the uMAP plots because they just seem to show a more clear picture of the relationships between clusters, but this script will run both and let you choose which you prefer. 

[See here](https://towardsdatascience.com/tsne-vs-umap-global-structure-4d8045acba17) for a look at the mathematical differences between the two.

The report that is generated downstream from this presents only the umap plots. Of course you can switch to showing the tsne plots instead but you should have a good reason to deviate from the standard. Also, I'd avoid showing both just to avoid confusion. 


### uMAP dimensionality reduction plot.

```{r create_umap, warning=FALSE,error=FALSE,message=FALSE}
experiment.aggregate <- RunUMAP(
  object = experiment.aggregate,
  reduction.use = "pca",
  dims = use.pcs,
  do.fast = TRUE)
```


### tSNE dim reduction plot.

tSNE dimensionality reduction plots are then used to visualize clustering results. As input to the tSNE, you should use the same PCs as input to the clustering analysis.

```{r create_tsne, warning=FALSE,error=FALSE,message=FALSE}
experiment.aggregate <- RunTSNE(
  object = experiment.aggregate,
  dims = use.pcs)
```

### Here are uMAPs of the different resolutions
```{r umap_group_plots_1, warning=FALSE,error=FALSE,message=FALSE, echo=FALSE, fig.width = 12, fig.height = 12}
umap.dimplot.1 <- DimPlot(object = experiment.aggregate, 
                          group.by=grep("res",colnames(experiment.aggregate@meta.data),
                                        value = TRUE)[1:4], 
                          ncol=2, 
                          pt.size=1, 
                          reduction = "umap", 
                          label = T)

umap.dimplot.1
save_png_plot(plot = umap.dimplot.1, filename = "umap_dimplot1.png")
# for(i in 1:8) { 
#   umap.dimplot <- DimPlot(object = experiment.aggregate, 
#                             group.by=grep("res",colnames(experiment.aggregate@meta.data), 
#                                           value = TRUE)[i],  
#                             pt.size=1.0,  
#                             reduction = "umap",  
#                             label = T)  
#   
#   umap.dimplot  
#   save_png_plot(plot = umap.dimplot.1, filename = paste0("umap_dimplot", i, ".png"))
# }
```

```{r umap_group_plots_2, warning=FALSE,error=FALSE,message=FALSE, echo=FALSE, fig.width = 12, fig.height = 12}
umap.dimplot.2 <- DimPlot(object = experiment.aggregate, group.by=grep("res",colnames(experiment.aggregate@meta.data),value = TRUE)[5:8], ncol=2 , pt.size=0.5, reduction = "umap", label = T)

umap.dimplot.2
save_png_plot(plot = umap.dimplot.2, filename = "umap_dimplot2.png")
```


<br/>
<br/>

### And Here are tSNE plots of the different resolutions

```{r tsne_group_plots_1, warning=FALSE,error=FALSE,message=FALSE,  echo=FALSE}
DimPlot(object = experiment.aggregate, group.by=grep("res",colnames(experiment.aggregate@meta.data),value = TRUE)[1:4], ncol=2 , pt.size=1.0, reduction = "tsne", label = T)
```

```{r tsne_group_plots_2, warning=FALSE,error=FALSE,message=FALSE,  echo=FALSE}
DimPlot(object = experiment.aggregate, group.by=grep("res",colnames(experiment.aggregate@meta.data),value = TRUE)[5:8], ncol=2 , pt.size=1.0, reduction = "tsne", label = T)
```

```{r doublet_prediction, warning=FALSE, error=FALSE, message=FALSE}

# split the dataset into a list of seurat objects
experiment.split <- SplitObject(experiment.aggregate, split.by = "orig.ident")

single.seurat.object <- experiment.split[[1]]
                                         
experiment.split <- lapply(X = experiment.split, FUN = function(single.seurat.object) { 
  sweep.res.list <- paramSweep(single.seurat.object,
                                    PCs = 1:num.pcs)
  
  sweep.stats <- summarizeSweep(sweep.res.list, GT = FALSE)
  bcmvn <- find.pK(sweep.stats)
  
  annotations <- single.seurat.object@meta.data$integrated_snn_res.0.1
  homotypic.prop <- modelHomotypic(annotations)
  nExp_poi <- round(0.075*nrow(single.seurat.object@meta.data))  ## Assuming 7.5% doublet formation rate - tailor for your dataset
  nExp_poi.adj <- round(nExp_poi*(1-homotypic.prop))
  
  ## Run DoubletFinder with varying classification stringencies ----------------------------------------------------------------
  single.seurat.object <- doubletFinder(experiment.aggregate,
                                           PCs = 1:10,
                                           pN = 0.25,
                                           pK = 0.09,
                                           nExp = nExp_poi,
                                           reuse.pANN = FALSE)

  single.seurat.object
})
```

```{r doublet_prediction_plot, warning=FALSE, error=FALSE, message=FALSE}

df.class.metadata.tag <- grep("DF.classifications",
                              colnames(experiment.aggregate@meta.data),
                              value = TRUE)

db.plot <- DimPlot(object = experiment.aggregate,
                   group.by=df.class.metadata.tag,
                   pt.size=0.5,
                   reduction = reduction.to.plot )

db.plot
save_png_plot(plot = db.plot, filename = "doublet_dimplot.png")
```


And last lets save all the objects in our session.
```{r save_rdata, warning=FALSE,error=FALSE,message=FALSE}
saveRDS(experiment.aggregate, file=part4.rds.save.path)

# to.save.for.report <- c("clusters.by.resolution.table",
#                         "umap.dimplot.1",
#                         "umap.dimplot.2",
#                         "db.plot")

save(clusters.by.resolution.table, file=part4.file.report.path)
```

## Session Information
```{r session_info, warning=FALSE,error=FALSE,message=FALSE}
sessionInfo()
```
